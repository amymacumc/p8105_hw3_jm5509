p8105_hw3_jm5509
================
Echo
2022-10-15

## Problem 1

This problem uses the Instacart data.The goal is to do some exploration
of this dataset. How many aisles are there, and which aisles are the
most items ordered from?

``` r
data("instacart")
(instacart %>% group_by(aisle) %>% count() %>% nrow())
```

    ## [1] 134

``` r
(instacart %>% group_by(aisle_id) %>% count() %>% nrow())
```

    ## [1] 134

Make a plot that shows the number of items ordered in each aisle,
limiting this to aisles with more than 10000 items ordered. Arrange
aisles sensibly, and organize your plot so others can read it.

``` r
instacart %>% group_by(aisle) %>% 
  summarize(n_ordered = n()) %>% 
  filter(n_ordered > 10000) %>% 
  arrange(desc(n_ordered)) %>% 
  mutate(aisle = fct_reorder(aisle, n_ordered)) %>% 
  ggplot(aes(y=aisle, x= n_ordered, fill=aisle))+
  geom_col()+
  labs(
     title = "Number of items ordered in every aisle",
      x = "Aisle",
      y = "Number of items ordered") +
  theme(legend.position = "none")
```

![](p8105_hw3_jm5509_new_files/figure-gfm/unnamed-chunk-3-1.png)<!-- -->
Make a table showing the three most popular items in each of the aisles
“baking ingredients”, “dog food care”, and “packaged vegetables fruits”.
Include the number of times each item is ordered in your table.

``` r
instacart %>% 
  filter(aisle == c('baking ingredients', 
                    'dog food care', 'packaged vegetables fruits')) %>%
  group_by(aisle, product_name) %>% 
  summarize(n_product = n()) %>% 
  filter(min_rank(desc(n_product)) <= 3) %>% 
  knitr::kable()
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the
    ## `.groups` argument.

| aisle                      | product_name                                    | n_product |
|:---------------------------|:------------------------------------------------|----------:|
| baking ingredients         | Light Brown Sugar                               |       157 |
| baking ingredients         | Organic Vanilla Extract                         |       122 |
| baking ingredients         | Pure Baking Soda                                |       140 |
| dog food care              | Organix Chicken & Brown Rice Recipe             |        13 |
| dog food care              | Organix Grain Free Chicken & Vegetable Dog Food |        14 |
| dog food care              | Original Dry Dog                                |         9 |
| packaged vegetables fruits | Organic Baby Spinach                            |      3324 |
| packaged vegetables fruits | Organic Blueberries                             |      1692 |
| packaged vegetables fruits | Organic Raspberries                             |      1920 |

As is shown above, the top 3 baking ingredients are `light brown sugar`,
`organic vanilla extract`, and `pure baking soda`; the top 3 dog food
cares are `Organix Chicken & Brown Rice Recipe`,
`Organix Grain Free Chicken & Vegetable Dog Food`, and
`Original Dry Dog`; the top 3 packaged vegetables fruits are
`Organic Baby Spinach`, `Organic Blueberries`, `Organic Raspberries`.
Comparing the sales volumes, the `packaged vegetables fruits` category
is the most popular one among the three.

Finally, for each day of the week, a table shows the average hour of the
day when Pink Lady Apples and Coffee Ice Cream are ordered. For human
readers, this table has been structured in an untidy manner. With the
exception of day 5, Pink Lady Apples are normally purchased
significantly earlier in the day than Coffee Ice Cream.

``` r
instacart %>% 
  filter(product_name == c('Pink Lady Apples','Coffee Ice Cream')) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(
    mean_order_hour = mean(order_hour_of_day)
  ) %>% 
  mutate(order_dow = recode(order_dow, `0` = 'Sunday', `1` =' Monday',
                            `2` = 'Tuesday', `3` = 'Wednesday',
                            `4` = 'Thursday', `5` = 'Friday',
                            `6` = 'Saturday')) %>% 
  pivot_wider(names_from = order_dow, values_from = mean_order_hour) %>% 
  knitr::kable()
```

    ## Warning in product_name == c("Pink Lady Apples", "Coffee Ice Cream"): longer
    ## object length is not a multiple of shorter object length

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

| product_name     |   Sunday |   Monday |  Tuesday | Wednesday | Thursday |   Friday | Saturday |
|:-----------------|---------:|---------:|---------:|----------:|---------:|---------:|---------:|
| Coffee Ice Cream | 13.22222 | 15.00000 | 15.33333 |   15.4000 | 15.16667 | 10.33333 | 12.35294 |
| Pink Lady Apples | 12.25000 | 11.67857 | 12.00000 |   13.9375 | 11.90909 | 13.86957 | 11.55556 |

## Problem 2

This question is about dealing with the accelerometers data. I would
read the data first, and tidying it by adding one a weekday vs weekend
variable, and changing the variables of activity every minute into
observations by *pivot_longer()* function. In this case this dataframe
would have useful names.

``` r
(accel_df <- read_csv('accel_data.csv') %>% 
  janitor::clean_names() %>% 
  rename_with(~str_replace(., regex('^activity_'),'')) %>% 
  mutate(weekday_vs_weekend =
           ifelse(day %in% c('Monday', 'Tuesday', 'Wednesday',
                             'Thursday', 'Friday'), 'weekday', 'weekend')) %>% 
  pivot_longer('1':'1440', names_to = 'minute', values_to = 'activity') %>% 
  mutate(minute = as.integer(minute)) 
 )
```

    ## Rows: 35 Columns: 1443
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

    ## # A tibble: 50,400 × 6
    ##     week day_id day    weekday_vs_weekend minute activity
    ##    <dbl>  <dbl> <chr>  <chr>               <int>    <dbl>
    ##  1     1      1 Friday weekday                 1     88.4
    ##  2     1      1 Friday weekday                 2     82.2
    ##  3     1      1 Friday weekday                 3     64.4
    ##  4     1      1 Friday weekday                 4     70.0
    ##  5     1      1 Friday weekday                 5     75.0
    ##  6     1      1 Friday weekday                 6     66.3
    ##  7     1      1 Friday weekday                 7     53.8
    ##  8     1      1 Friday weekday                 8     47.8
    ##  9     1      1 Friday weekday                 9     55.5
    ## 10     1      1 Friday weekday                10     43.0
    ## # … with 50,390 more rows

This produces a dataframe with **50400** observations and **6**
variables. The variables are **week, day_id, day, weekday_vs_weekend,
minute, activity**.

To better use the activity data, we can aggregate across minutes to
create a total activity variable for each day. Then I plot these
activity per day to see if there is an activity trend.

``` r
accel_df %>% group_by(week, day_id, day) %>% 
  summarize(total_activity = sum(activity))
```

    ## `summarise()` has grouped output by 'week', 'day_id'. You can override using
    ## the `.groups` argument.

    ## # A tibble: 35 × 4
    ## # Groups:   week, day_id [35]
    ##     week day_id day       total_activity
    ##    <dbl>  <dbl> <chr>              <dbl>
    ##  1     1      1 Friday           480543.
    ##  2     1      2 Monday            78828.
    ##  3     1      3 Saturday         376254 
    ##  4     1      4 Sunday           631105 
    ##  5     1      5 Thursday         355924.
    ##  6     1      6 Tuesday          307094.
    ##  7     1      7 Wednesday        340115.
    ##  8     2      8 Friday           568839 
    ##  9     2      9 Monday           295431 
    ## 10     2     10 Saturday         607175 
    ## # … with 25 more rows

``` r
accel_df %>% group_by(week, day_id, day) %>% 
  summarize(total_activity = sum(activity)) %>% 
  ggplot(aes(x=day, y = total_activity, fill = week)) +
  geom_col(position = 'dodge2') +
  labs(
     title = "Trends of a total activity for each day",
      x = "Day",
      y = "Activity") 
```

    ## `summarise()` has grouped output by 'week', 'day_id'. You can override using
    ## the `.groups` argument.

![](p8105_hw3_jm5509_new_files/figure-gfm/aggregate%20and%20plot-1.png)<!-- -->

``` r
accel_df %>% group_by(week, day_id, day) %>% 
  summarize(total_activity = sum(activity)) %>% 
  ggplot(aes(x=day_id, y = total_activity, color = day))+
  geom_point()+geom_line()
```

    ## `summarise()` has grouped output by 'week', 'day_id'. You can override using
    ## the `.groups` argument.

![](p8105_hw3_jm5509_new_files/figure-gfm/aggregate%20and%20plot-2.png)<!-- -->

From the column chart and the line chart above, there is no apparent
within-week and between-week trend. However, there are some outliers
that the last two Saturdays’ activities are obviously lower than any
other days, which is 1440. Both the within-week and the between-week
activity vary a lot.
